# -*- coding: utf-8 -*-
"""Hecca

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TQEddEJhjR_EOs7OZ3b00npj-Cv6exjD

#Preparación: funciones, clases, librerias, etc.

##entrada drive
"""
"""""
from google.colab import drive
drive.mount('/content/drive')
!pip install rpy2==3.5.1

"""  # librerias """

# from IPython.display import clear_output
# import matplotlib.pyplot as plt
# import rpy2.robjects as robjects
# from rpy2.robjects.packages import importr
# from rpy2.robjects.vectors import StrVector
# import scipy.stats as stats
# from sklearn.linear_model import LinearRegression
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import r2_score
# from sklearn.metrics import mean_squared_error
# import statsmodels.api as sm
# import statsmodels.formula.api as smf
# import seaborn as sns

"""##clases"""




import pandas as pd
import numpy as np
import datetime
from datetime import date as todaysDate
from datetime import datetime as todaysDateTime
from numpy.ma.core import empty
class Evento_completo:  # reune todas las caracteristicas del evento como magnitud, intensidad, etc. también reune el evento en sí en un df.
    mes = -1
    magnitud = -1.0
    intensidad = -1.0
    duracion = -1

    def __init__(self, df1, umbral, umbralstr):
        self.df1 = df1.copy()
        self.umbral = umbral
        self.umbralstr = umbralstr
        self.organizar_df()
        self.set_intensidad()
        self.organizar_mes()

    def organizar_df(self):
        self.df1 = self.df1[['cuenca-base', self.umbralstr]]
        self.df1[self.umbralstr] = abs(self.df1['cuenca-base']-self.umbral)

    def set_intensidad(self):
        self.magnitud = self.df1[self.umbralstr].sum()
        self.duracion = self.df1[self.umbralstr].size
        self.intensidad = self.magnitud/self.duracion

    def organizar_mes(self):
        if (self.df1.index.min().month != self.df1.index.max().month):
            max_1 = self.df1.index.max().month
            min_1 = self.df1.index.min().month
            if (self.df1['cuenca-base'][self.df1.index.month == max_1].size > self.df1['cuenca-base'][self.df1.index.month == min_1].size):
                self.mes = max_1
            else:
                self.mes = min_1
        else:
            self.mes = self.df1.index.min().month


"""##funciones

###funciones utilitarias: llenado de datos y esas cosas, luego ampliare esto de acuerdo a lo que halla
"""


def fecha_cruda(df1):
    '''recibe un dataframe crudo y devuelve el porcentaje de datos faltantes, la fecha inicial y final completa y los años utilizables'''
    funcional = verificar_columnas(df1)
    if (funcional):
        df2 = organize_df(df1)
        a = summarize_missing_values(df2)[0]
        c = summarize_missing_values(df2)[1] 
        b = prim_ult(df2)
        data=[True,a,c,b[2]]
        return data
    else:
        return False


def verificar_columnas(dataframe):
    if set(['Valor', 'Fecha']).issubset(set(dataframe.columns)):
        return True
    else:
        return False


'''
a=fecha_cruda(read_data3)
print(type(a))
print(a)
'''


def prim_ult(df1):
    '''recibe un dataframe y devuelve la fecha minima la fecha maxima y la cantidad de años completos entre ellas'''
    # print("La primera fecha es: ", df1.index[0])
    # print("La última fecha es: ", df1.index[-1])
    # Se necesitan años completos entonces
    min_date = datetime.date(
        df1.index[0].year, df1.index[0].month, df1.index[0].day)
    if min_date.month != 1 or min_date.day != 1:
        min_date = datetime.date(df1.index[0].year + 1, 1, 1)
    max_date = datetime.date(
        df1.index[-1].year, df1.index[-1].month, df1.index[-1].day)
    if max_date.month != 12 or max_date.day != 31:
        max_date = datetime.date(df1.index[-1].year - 1, 12, 31)
    # print("La primera fecha que se tendrá en cuenta es", min_date)
    # print("La última fecha que se tendrá en cuenta es", max_date)
    delta_anios = max_date.year-min_date.year+1
    delta_anios
    if (delta_anios < 15):
        pass
        # print("vamos mal bro, busque una serie que sirva")
    else:
        pass
        # print("bien bro, seguimos")
    min = int(min_date.year)
    max = int(max_date.year)
    return min_date, max_date, delta_anios


"""###funciones de llenado """

# Función para resumir la información de los datos faltantes


def summarize_missing_values(complete_data):
    '''Función para resumir la información de los datos faltantes, recibe un dataframe e imprime las fechas sin datos, el numero de datos faltantes y el porcentaje de datos faltante'''
    mask = complete_data.isna()
    list_missing_values = complete_data[mask['Valor'] == True].index
    #print("Las fechas que no tienen valor son:\n", list_missing_values)

    length_missing_values = len(list_missing_values)
    #print("El número de datos faltantes es: ", length_missing_values)

    length_total_values = len(complete_data)
    ratio_missing_values = length_missing_values/length_total_values
    #print("Lo que representa un {:.3%} de todos los datos".format(
        #ratio_missing_values))
    return [ratio_missing_values, length_missing_values]


"""Llenado completo"""


def process_df(df_base, df_apoyo=None, areas=None):
    """
      Procesa un DataFrame con o sin un DataFrame de apoyo para llenar los valores NaN en el primer DataFrame.

      Parameters
      ----------
      df_base: pandas.DataFrame
          El DataFrame principal a procesar.
      df_apoyo: pandas.DataFrame, opcional
          El DataFrame de apoyo que se utilizará para llenar los valores NaN en df_base. Por defecto es None.
      areas: tuple, opcional
          Las áreas que se usarán para calcular las proporciones. Por defecto es None.

      Returns
      -------
      pandas.DataFrame
          El DataFrame df_base procesado con los valores NaN reemplazados, si es posible.
      """
    if df_apoyo is not None:
        df_base, df_apoyo = organize_df(df_base, df_apoyo)
    else:
        df_base = organize_df(df_base)
    if areas is not None:
        area1, area2 = areas
        df_base = df_base / area1
        df_apoyo = df_apoyo / area2
    if df_apoyo is not None:
        df_base_2, df_apoyo_2 = fill_na_values(df_base, df_apoyo)
        X = df_apoyo_2.values.reshape(-1, 1)
        Y = df_base_2.values
        # model = LinearRegression().fit(X, Y)
        # slope = model.coef_[0]
        # intercept = model.intercept_
        # new_series = slope * df_apoyo + intercept
        # df_base = df_base.fillna(new_series)
    df_base = fill_data_na(df_base)
    df_return = sacar_anios(df_base)
    return df_return


def organize_df(df_base, df_apoyo=None):
    """
      Esta función recibe dos DataFrames, uno obligatorio `df_base` y otro opcional `df_apoyo`. 
      La función convierte la columna 'Fecha' en tipo datetime y reindexa los DataFrames con un rango de fechas completo desde la primera hasta la última fecha presente en `df_base`.
      Si `df_apoyo` es diferente de None, también se procesa `df_apoyo` y se retornan ambos DataFrames reindexados. 
      En caso contrario, solo se retorna `df_base` reindexado.

      Argumentos:
      df_base -- un DataFrame con dos columnas 'Fecha' y 'Valor'
      df_apoyo -- un DataFrame con dos columnas 'Fecha' y 'Valor' (opcional)

      Retorna:
      (base, apoyo) -- tupla con los DataFrames `df_base` y `df_apoyo` reindexados (si `df_apoyo` no es None)
      base -- el DataFrame `df_base` reindexado (si `df_apoyo` es None)
      """
    base = df_base[['Fecha', 'Valor']].copy()
    base['Fecha'] = pd.to_datetime(base['Fecha'])
    size = base['Fecha'].size
    days = pd.date_range(base.at[0, 'Fecha'], base.at[size-1, 'Fecha'])
    days_ind = pd.DatetimeIndex(days)
    base = base.set_index('Fecha')
    base = base.reindex(days)
    if df_apoyo is not None:
        apoyo = df_apoyo[['Fecha', 'Valor']].copy()
        apoyo['Fecha'] = pd.to_datetime(apoyo['Fecha'])
        apoyo = apoyo.set_index('Fecha')
        apoyo = apoyo.reindex(days)
        return base, apoyo
    else:
        return base


def fill_na_values(df_base, df_apoyo):
    """
      Elimina las filas en dos DataFrames donde al menos un valor es NaN.

      Parameters
      ----------
      df_base: pandas.DataFrame
          El DataFrame principal a procesar.
      df_apoyo: pandas.DataFrame
          El DataFrame de apoyo que se utilizará para llenar los valores NaN en df_base.

      Returns
      -------
      tuple (pandas.DataFrame, pandas.DataFrame)
          Una tupla con los dos DataFrames sin filas con NaN.
      """
    mask = df_base.isna() | df_apoyo.isna()
    df_base = df_base[~mask].copy()
    df_apoyo = df_apoyo[~mask].copy()
    df_base.dropna(inplace=True)
    df_apoyo.dropna(inplace=True)
    return df_base, df_apoyo


def fill_data_na(data):
    """
      Completa los valores faltantes en el DataFrame `data` utilizando el promedio del día y mes correspondiente.

      Argumentos:
      data: pandas.DataFrame
          DataFrame con los datos a completar. Debe tener una columna 'cuenca-base' que es la que se completará.

      Retorna:
      pandas.DataFrame
          DataFrame con los valores faltantes completados.
      """
    complete_data_day_month = data.groupby(
        by=[data.index.day, data.index.month])
    complete_data_day_month_description = complete_data_day_month.describe()

    def fill_caudal_day(row):
        """
        Función auxiliar que completa un valor faltante en la columna 'Valor' en el DataFrame `data`.

        Argumentos:
        row: pandas.Series
            Fila en el DataFrame con los datos a completar.

        Retorna:
        float
            El valor completado para la columna 'Valor'.
        """
        if np.isnan(row['Valor']):
            summary_day = complete_data_day_month_description.loc[row.name.day, row.name.month]
            return complete_data_day_month_description.loc[row.name.day, row.name.month].loc[('Valor', 'mean')]
        return row['Valor']
    data['Valor'] = data.apply(fill_caudal_day, axis=1)
    return data


def sacar_anios(df1):
    """
      Función que recorta un DataFrame `df1` indexado con fechas, eliminando el año correspondiente a la primera y última fechas.

      Argumentos:
      df1: pandas.DataFrame
          DataFrame indexado con fechas que se quiere recortar.

      Retorna:
      pandas.DataFrame
          DataFrame con el mismo contenido que `df1` pero sin el año correspondiente a la primera y última fechas.
      """
    min_date, max_date, delta_anios = prim_ult(df1)
    Today_time = todaysDateTime.min.time()
    min_date_corr = todaysDateTime.combine(min_date, Today_time)
    max_date_corr = todaysDateTime.combine(max_date, Today_time)
    df1 = df1[df1.index >= min_date_corr][df1[df1.index >=
                                              min_date_corr].index <= max_date_corr].copy()
    return df1


"""###funciones estadisticas"""


# esta funcion realiza el ttest, pendiende de análisar
def ttest_pvalue_rpy2(d1, d2, equal_vari):
    '''recibe dos series de r.objects además de un boolean de si las varianzas son iguales y devuelve el t test hecho en R'''
    rd1 = d1
    rd2 = d2
    # rttest=robjects.r['t.test']
    # a=robjects.r['t.test'](d1,d2,'two.sided',0,True)
    # a=robjects.r['t.test'](d1,d2,'two.sided',0,False,equal_vari)
    # return a


def Ftest_pvalue_rpy2(d1, d2):
    """recibe dos pandas series d1 y d2 los convierte en robjects y devuelve el f test"""
    # rd1 = (robjects.FloatVector(d1))
    # rd2 = (robjects.FloatVector(d2))
    # rvtest = robjects.r['var.test']
    # return rvtest(rd1,rd2)[2][0]


def inv_t_test_b(alfa, free_deg):
    '''recibe un valor flotante (alfa) y un valor entero (free_deg) y devuelve el t test inverso de forma b'''
    # return (stats.t.ppf((1-(1-alfa)/2), free_deg))


def inv_t_test_a(alfa, free_deg):
    '''recibe un valor flotante (alfa) y un valor entero (free_deg) y devuelve el t test inverso de forma a'''
    # return (stats.t.ppf((1-alfa/2), free_deg))


def promedio_serie(s1, prueba):
    if (prueba):
        return s1.mean()
    return -1


def varianza_serie(s1, prueba, magnitud, alt):
    if (prueba):
        if (alt):
            return s1.var()
        if (magnitud):
            return s1.var()
        if (s1.mad() > 1):
            return s1.var()
    if (alt):
        return -2
    return -1


def prueba_f_serie(s1, s2, var1, var2):  # -1 ="no calcular" -2="revisar"
    if (var1 == -1):
        return -1
    if ((var2 == 0) or (var2 == -2)):
        return -2
    # x=robjects.FloatVector(s1)
    # y=robjects.FloatVector(s2)
    # return Ftest_pvalue_rpy2(x,y) #pruebaf


def lib_grad(s1, s2, var1, var2, pruebaf):  # -1 = "no calcular " -2 = "revisar"
    if (pruebaf == -2):
        return -2
    if ((var1 == -1) or (var2 == -2)):
        return -1
    if (s1.size+s2.size-2 < 0):
        return -1
    return (s1.size+s2.size-2)


# -2000000 = "revisar" -1000000 = "no calcular"
def prueba_t_serie(s1, s2, pruebaf, grados_lib):
    if (grados_lib == -2):
        return -2000000
    if (grados_lib == -1):
        return -1000000
    if (pruebaf < 0.05):
        equal_var = False
    else:
        equal_var = True
    # s1=
    return ttest_pvalue_rpy2(s1, s2, equal_var)[2][0]


def anti_t_student(t_st, glib, dug):
    if (t_st == -2000000):
        return t_st
    if (glib == -1):
        return -1000000
    if (dug):
        return inv_t_test_a(t_st, glib)
    return inv_t_test_b(t_st, glib)


def prueba_si_cumple(sb, sa, mes, duracion, magintud):
    prub = Prueba_porc(sb, mes, True, duracion)
    prua = Prueba_porc(sa, mes, False, duracion)
    mean_base = promedio_serie(sb, prub)
    mean_alt = promedio_serie(sa, prua)
    var_base = varianza_serie(sb, prub, magintud, False)
    var_alt = varianza_serie(sa, prua, magintud, True)
    F1 = prueba_f_serie(sb, sa, var_base, var_alt)
    lib1 = lib_grad(sb, sa, var_base, var_alt, F1)
    # s1=robjects.FloatVector(sb)
    # s2=robjects.FloatVector(sa)
    # Tst=prueba_t_serie(s1,s2,F1,lib1)
    # anti_tst=anti_t_student(Tst,lib1,True)
    valor_confianza = anti_t_student(0.95, lib1, False)
    # if(anti_tst==-1000000):
    # return True
    # if(anti_tst==-2000000):
    # return False
    # return abs(anti_tst)<abs(valor_confianza)


def cumple(dfb, dfa, mes):  # dfb =ref dfa = alterada
    sb = dfb['Magnitud'][dfb['mes'] == mes]
    sa = dfa['Magnitud'][dfa['mes'] == mes]
    boola = prueba_si_cumple(sb, sa, mes, False, True)
    sb = dfb['Duracion'][dfb['mes'] == mes]
    sa = dfa['Duracion'][dfa['mes'] == mes]
    boolb = prueba_si_cumple(sb, sa, mes, True, False)
    sb = dfb['Intensidad'][dfb['mes'] == mes]
    sa = dfa['Intensidad'][dfa['mes'] == mes]
    boolc = prueba_si_cumple(sb, sa, mes, False, False)
    return ((boola and boolb) & (boolc))
# s1 serie de eventos, mes, mes, es_ref <- ref o no, es_duracion <- duracion o no


def Prueba_porc(s1, mes, es_ref, es_duracion):
    if (es_ref):  # si es ref
        porc_aprov = df2.iat[mes-1, 3]
        tam_ref = s1.size
        prueba_est = tam_ref/porc_aprov
        if (prueba_est > 0.05):  # si la prueba est es mayor al 5%
            if (tam_ref > 1):  # si tiene mas de un dato
                return True
            return False
        return False
    if (not (es_duracion)):
        if (s1.size > 1):
            return True
        return False
    if ((s1.size > 1) and (not (s1.mean() == 1))):
        return True
    return False


"""###funciones del algoritmo

####minimos
"""

df_prueba = pd.DataFrame()


def minimos():
    """
      calcula los umbrales QTR 15, QTQ, QB y Q10, además del minimo revisado por año.

      Parameters
      ----------
      data: pandas.DataFrame
          El DataFrame principal a procesar.

      Returns
      -------
      tuple ( pandas.DataFrame)
        el dataframe con los minimos y promedios revisados
        los umbrales se guardan en las variables globales
      """
    global QTR_15
    global QTQ
    global QB
    global Q10
    global data
    global df_prueba
    # df es un dataframe temporar que se sobreescribe eventualmente
    df = pd.DataFrame()
    # set columns
    df = df.assign(Fecha=None, Min=None, Max=None, Mean=None)
    # se crea un dataframe en donde se calculan los minimos máximos y promedio por mes y año
    for i in range(data.index.min().year, data.index.max().year+1):
        for j in range(1, 13):
            '''idx=np.where((data['Fecha'].dt.month==j)&(data['Fecha'].dt.year==i))
            data_filter=data.loc[idx]'''
            # filtro los datos por año y mes para hacer el analisis
            data_filter = data[data.index.year ==
                               i][data[data.index.year == i].index.month == j]
            row = [str(i)+str(-j), data_filter['cuenca-base'].min(),
                   data_filter['cuenca-base'].max(), data_filter['cuenca-base'].mean()]
            df.loc[len(df)] = row
    # data view
    df['Fecha'] = pd.to_datetime(df['Fecha'])
    df = df.set_index('Fecha')
    df_prueba = df
    '''
  se crea listas con n valores, siendo n el número de años en el dataset, guardando el máximo y minimo por año
  '''
    mins = []
    maxs = []
    for i in range(df.index.min().year, df.index.max().year):
        mins.append(df[df.index.year == i]['Min'].min())
        maxs.append(df[df.index.year == i]['Max'].max())
    mins = np.array(mins)
    maxs = np.array(maxs)
    mean_min = (mins.mean())
    std_min = (np.std(mins))  # desviacion estandar
    coef_variacion_min = std_min/mean_min
    mean_max = (maxs.mean())
    std_max = (np.std(maxs))
    alpha_min = 1.0079*(coef_variacion_min**-1.084)
    a_alpha_min = (-0.0607*(coef_variacion_min**3))+(0.5502 *
                                                     (coef_variacion_min**2))-(0.4937*coef_variacion_min)+1.003
    beta = (a_alpha_min/mean_min)**(-1)
    # umbrales QTQ y QB
    #
    umbral_QTQ = beta*((-np.log(1-(1/2)))**(1/alpha_min))
    umbral_Q10 = beta*((-np.log(1-(1/10)))**(1/alpha_min))
    #
    ##
    # crea un dataframe donde poner los minimos y maximos por mes de toda la serie
    df = pd.DataFrame()
    # set columns
    df = df.assign(Fecha=None, Min=None, Max=None,
                   Mean=None, Min_rev=None, Mean_rev=None)
    # calculate mim, max, mean, min_rev and mean_rev
    for i in range(data.index.min().year, data.index.max().year+1):
        for j in range(1, 13):
            # filtro los datos por año y mes para hacer el analisis
            data_filter = data[data.index.year ==
                               i][data[data.index.year == i].index.month == j]
            row = [str(i)+str(-j), data_filter['cuenca-base'].min(), data_filter['cuenca-base'].max(), data_filter['cuenca-base'].mean(),
                   data_filter['cuenca-base'][data['cuenca-base'] > umbral_Q10].min(), data_filter['cuenca-base'][data['cuenca-base'] > umbral_Q10].mean()]
            df.loc[len(df)] = row
    df['Fecha'] = pd.to_datetime(df['Fecha'])
    df = df.set_index('Fecha')
    alpha_max = (np.sqrt(6)*std_max)/(np.pi)
    u_max = mean_max-(0.5772*alpha_max)
    yt_QB = -np.log(np.log(2.33/(2.33-1)))
    yt_Q15 = -np.log(np.log(15/(15-1)))
    # umbrales QB y QTR15
    #
    umbral_QB = u_max+(yt_QB*alpha_max)
    umbral_Q15 = u_max+(yt_Q15*alpha_max)
    #
    ##
    QTR_15 = umbral_Q15
    QB = umbral_QB
    QTQ = umbral_QTQ
    Q10 = umbral_Q10
    return df


"""####funcion principal"""


def prin_func(crud_base, crud_apoyo=None, areas=None):
    global df_prueba
    global QTR_15
    global QB
    global QTQ
    global Q10
    global df_qtq_ref
    global df_qtq_alt
    global df_qb_ref
    global df_qb_alt
    global data
    global df2
    global primer_dia
    global dif
    global final_dia
    df_funcional = process_df(crud_base, crud_apoyo, areas)
    df_funcional = df_funcional.rename(columns={'Valor': 'cuenca-base'})
    data = df_funcional
    df_rev = minimos()
    org_df2_1(df_rev)
    for i in range(1, 13):
        org_df2_2(1, i)
    data = df_funcional.copy()
    primer_dia = data.index.min()
    final_dia = data.index.max()
    segundo_dia = data[data.index > data.index.min()].index.min()
    dif = segundo_dia-primer_dia
    nombrar_evento(data, 'cuenca-base')
    contar_eventos(data, 'event_QTR15', eventos_qtr15, 'event_QTR15', QTR_15)
    contar_eventos(data, 'event_QB', eventos_qb, 'event_QTR15', QB)
    contar_eventos(data, 'event_QTQ', eventos_qtq, 'event_Q10', QTQ)
    contar_eventos(data, 'event_Q10', eventos_q10, 'event_Q10', Q10)
    df_qtq_ref = DF_eventos(df_qtq_ref, eventos_qtq)
    df_qb_ref = DF_eventos(df_qb_ref, eventos_qb)
    formar_alter()
    org_alt()
    for j in range(3):
        for i in range(1, 13):
            print(i)
            calibrar_mes(i)
    return df2


"""####otra cosa"""


def org_alt():
    global df_qtq_alt
    global df_qb_alt
    global eventos_rev_qtr15
    global eventos_rev_qb
    global eventos_rev_qtq
    global eventos_rev_q10
    global QTR_15
    global Q10
    global QB
    global QTQ
    df_qtq_alt = pd.DataFrame()
    df_qb_alt = pd.DataFrame()
    df_qtq_alt.assign(mes=None, Magnitud=None, Intensidad=None, Duracion=None)
    df_qb_alt.assign(mes=None, Magnitud=None, Intensidad=None, Duracion=None)
    eventos_rev_qtr15.clear()
    eventos_rev_qb.clear()
    eventos_rev_qtq.clear()
    eventos_rev_q10.clear()
    nombrar_evento(data_alter2, 'cuenca-base')
    contar_eventos(data_alter2, 'event_QTR15',
                   eventos_rev_qtr15, 'event_QTR15', QTR_15)
    contar_eventos(data_alter2, 'event_QB', eventos_rev_qb, 'event_QTR15', QB)
    contar_eventos(data_alter2, 'event_QTQ', eventos_rev_qtq, 'event_Q10', QTQ)
    contar_eventos(data_alter2, 'event_Q10', eventos_rev_q10, 'event_Q10', Q10)
    df_qtq_alt = DF_eventos(df_qtq_alt, eventos_rev_qtq)
    df_qb_alt = DF_eventos(df_qb_alt, eventos_rev_qb)


def formar_alter():
    global data_alter
    global data_alter2
    global df2
    global data
    global df_prueba
    data_alter = data[['cuenca-base']].copy()
    data_alter['Aprov_teo'] = np.NaN
    data_alter['check_3'] = np.NaN
    data_alter['check_2'] = np.NaN
    data_alter['Q_ajustado'] = np.NaN
    data_alter['Q_ambiental'] = np.NaN
    data_alter['Q_aprov_real'] = np.NaN
    for i in range(1, 13):
        # serie booleana si pertenece al mes correcto
        a_bool = data_alter.index.month == i
        # aprovechamiento teorico = aprovechamiento teorico de ese mes ########
        data_alter['Aprov_teo'].loc[a_bool] = df2.iat[i-1, 4]
        # check 3 igual al minimo revisado ########
        data_alter['check_3'].loc[a_bool] = df2.iat[i-1, 1]
        # s.b. si el Q obs es > que el aprov teorico
        b_bool = data_alter['cuenca-base'] > data_alter['Aprov_teo']
        # s.b. si pertenece al mes correcto y es Q obs es > que el aprov teorico
        c_bool = (a_bool) & (b_bool)
        # s.b. si pertenece al mes correcto y es Q obs es < que el aprov teorico
        d_bool = (a_bool) & (~(b_bool))
        # s.b. si el Q obs es < al minimo revisado
        e_bool = data_alter['cuenca-base'] < data_alter['check_3']
        # Si mes correcto & Q obs < aprov teo & Q obs < check 3
        f_bool = (d_bool) & (e_bool)
        # s.b. si pertenece al mes correcto y el Q obs es > al minimo revisado & Q obs es < aprov teorico
        g_bool = (d_bool) & (~(e_bool))
        # Q obs > aprov teorico = aprov teorico #########
        data_alter['Q_ajustado'].loc[c_bool] = df2.iat[i-1, 4]
        # Q obs < aprov teorico = 0 #########
        data_alter['Q_ajustado'].loc[f_bool] = 0
        data_alter['Q_ajustado'].loc[g_bool] = data_alter['cuenca-base'][g_bool] - \
            data_alter['check_3'][g_bool]
        data_alter['check_2'] = data_alter['cuenca-base'] - \
            data_alter['Q_ajustado']  # check 2 = Q obs - Q ajustado
    a_bool = data_alter['cuenca-base'] < data_alter['check_3']
    b_bool = data_alter['check_2'] < data_alter['check_3']
    data_alter['Q_ambiental'].loc[a_bool] = data_alter['cuenca-base']
    data_alter['Q_ambiental'].loc[(~a_bool) & (b_bool)] = data_alter['check_3']
    data_alter['Q_ambiental'].loc[(~a_bool) & (
        ~b_bool)] = data_alter['check_2']
    data_alter['Q_aprov_real'] = data_alter['cuenca-base'] - \
        data_alter['Q_ambiental']
    data_alter2 = data_alter[['Q_ambiental']].copy()
    data_alter2.rename(columns={'Q_ambiental': 'cuenca-base'}, inplace=True)


def calibrar_mes(mess):
    inferior = 0
    superior = 1
    org_df2_2(1, mess)
    formar_alter()
    org_alt()
    i = mess
    if (cumple(df_qtq_ref, df_qtq_alt, i) and cumple(df_qb_ref, df_qb_alt, i)):
        return
    while (True):
        lim_prov = (inferior+superior)/2
        org_df2_2(lim_prov, mess)
        formar_alter()
        org_alt()
        if (cumple(df_qtq_ref, df_qtq_alt, i) and cumple(df_qb_ref, df_qb_alt, i)):
            inferior = lim_prov
            if (abs(inferior-superior) < 0.01):
                return
        else:
            superior = lim_prov


def org_df2_2(aprov, mes):  # porcentaje de aprovechamiento, mes, cambia el porcentaje de aprovechamiento de un mes escogido por el %escogido
    '''recibe un valor porcentual (aprov) y un valor entero (mes) y cambia el valor de aprovechamiento de ese mes ademas de cambiar el caudal aprovechado para ese mes'''
    global df2
    df2.loc[df2.index.month == mes, '%_aprov'] = aprov
    df2['Q_aprov'] = df2['Mean']*df2['%_aprov']


def org_df2_1(df):
    '''coge los valores de data(dataframe global) y los usa para crear el df2(df global) con 12 filas y 3 columnas (promedio, min_rev y mean_rev) por mes.'''
    global df2
    global data
    global df_prueba
    df2 = pd.DataFrame()
    # set columns
    df2 = df2.assign(Fecha=None, Mean=None, Min_rev=None, Mean_rev=None)
    # calculate mim, max, mean, min_rev and mean_rev
    i = data.index.min().year
    for j in range(1, 13):
        # filtro los datos por año y mes para hacer el analisis
        data_filter = df[df.index.month == j]
        row = [str(i)+str(-j), data_filter['Mean'].mean(),
               data_filter['Min_rev'].min(), data_filter['Mean_rev'].mean()]
        df2.loc[len(df2)] = row
    # data view
    df2['Fecha'] = pd.to_datetime(df2['Fecha'])
    df2 = df2.set_index('Fecha')


def DF_eventos(df_objetivo, lista_eventos):
    '''función toma un dataframe donde guardar las cosas y una lista con todos los eventos de la categoria que se le den y lo que hace es crear un dataframe con los datos de mes magnitud, etc. para luego poder acceder a ellos más fácil'''
    # set columns
    df_objetivo = df_objetivo.assign(
        mes=None, Magnitud=None, Intensidad=None, Duracion=None)
    # calculate mim, max, mean, min_rev and mean_rev
    for j in range(len(lista_eventos)):
        # filtro los datos por año y mes para hacer el analisis
        # data_filter=df[df.index.month==j]
        row = [lista_eventos[j].mes, lista_eventos[j].magnitud,
               lista_eventos[j].intensidad, lista_eventos[j].duracion]
        df_objetivo.loc[len(df_objetivo)] = row
    # data view
    return df_objetivo


def nombrar_evento(dfh, str4_h='cuenca-base'):
    '''funcion que coge un dataframe con datos de caudal y determina que días hubo eventos poniendo 1 o 0 donde sea necesario
    Parameters
    -----------
    dfh: dataframe al que se le van a encontrar los eventos
    str4_h: string con el valor 'cuenca-base' se necesita, aunque no se porque
    Return
    ----------
    nada
    '''
    global QTR_15
    global QB
    global QTQ
    global Q10
    umbral_Q15 = QTR_15
    umbral_QB = QB
    umbral_Q10 = Q10
    umbral_QTQ = QTQ
    dfh['event_QTR15'] = np.nan
    dfh['event_QB'] = np.nan
    dfh['event_QTQ'] = np.nan
    dfh['event_Q10'] = np.nan
    dfh.loc[dfh[str4_h] > umbral_Q15, 'event_QTR15'] = 1
    dfh.loc[dfh[str4_h] <= umbral_Q15, 'event_QTR15'] = 0
    ##
    dfh.loc[(dfh[str4_h] <= umbral_Q15) & (
        dfh[str4_h] > umbral_QB), 'event_QB'] = 1
    dfh.loc[~((dfh[str4_h] <= umbral_Q15) & (
        dfh[str4_h] > umbral_QB)), 'event_QB'] = 0

    dfh.loc[(dfh['cuenca-base'] > umbral_Q10) &
            (dfh['cuenca-base'] <= umbral_QTQ), 'event_QTQ'] = 1
    dfh.loc[~((dfh[str4_h] > umbral_Q10) & (
        dfh[str4_h] <= umbral_QTQ)), 'event_QTQ'] = 0
    ##

    dfh.loc[dfh['cuenca-base'] <= umbral_Q10, 'event_Q10'] = 1  # aqui
    dfh.loc[dfh[str4_h] > umbral_Q10, 'event_Q10'] = 0
    # data.fillna(0,inplace=True)


def contar_eventos(df21, eventosh, eventos_umbral, eventosi, umbral_caudal):
    global df2
    global primer_dia
    global dif
    global final_dia
    '''recibe un dataframe (df21) con los 1's ya puestos, un strin (eventosh) con el tipo de evento, una lista (eventos_umbral), otros string (eventosi) que es el evento umbral mayor, en caso de ser un evento medio y un flotante (umbral_caudal)con el valor del umbral, rellena las listas de eventos con bloques de eventos donde hayan 1's juntos, para formar eventos completos, en el caso de evento QB y QTQ también verifica que no hallan eventos QTR15 o Q10 inmediatamente anterior o siguiente al bloque'''
    inicio = primer_dia
    # inicio=data[data['event_QTR15']==1].index.min()
    final = data[(df21.index > inicio) & (df21[eventosh] == 0)].index.min()
    g = 0
    while (g < 700):
        # forma los bloques encontrando el primer 1 del df y el primer 0 después de ese 1 y haciendo un bloque de datos entre los dos y luego volviendolo a hacer
        # pero empeando desde el 0 anterior, hasta que acabe con el df o con el g<700 puesto por si hay algun problema no se quede pensando infinitamente
        inicio = df21[(df21[eventosh] == 1) & (
            df21.index > inicio)].index.min()
        final = df21[(df21[eventosh] == 0) & (df21.index > inicio)].index.min()
        if (df21[((df21.index >= inicio) & (df21.index <= df21.index.max())) & (df21[eventosh] == 0)].size == 0):
            final = df21.index.max()
        if ((not ((eventosh == 'event_QB') | (eventosh == 'event_QTQ'))) | (not ((any(df21[eventosi][(df21.index >= inicio-dif) & (df21.index < final+dif)]))))):
            if (df21[(df21.index >= inicio) & (df21.index < final)].size == 0):
                pass
            else:
                eventos_umbral.append(Evento_completo(df21[(df21.index >= inicio) & (
                    df21.index < final)].copy(), umbral_caudal, eventosh))
        inicio = final
        if (not (any(df21[eventosh][df21.index >= final]))):
            break
        # if (df21[(df21.index>=inicio)&(df21.index<final)].empty):
        #  break
        g = g+1
    inicio = primer_dia
    final = final_dia
    # eventos_rev_qtq[-1].df1.size


"""##variables globales

###umbrales
"""

QTR_15 = -1
QTQ = -1
QB = -1
Q10 = -1

print(QTR_15)
print(QTQ)
print(QB)
print(Q10)

"""###Provisionales"""

primer_dia = 1.0
dif = 1.0
final_dia = 1.0

DF_minimos_mensual = pd.DataFrame()

"""###listas de eventos"""

# natural
eventos_qtr15 = []
eventos_qb = []
eventos_qtq = []
eventos_q10 = []

# referencia
eventos_rev_qtr15 = []
eventos_rev_qb = []
eventos_rev_qtq = []
eventos_rev_q10 = []

"""###dataframes utiles"""

# data es el dataframe donde va a estar
data = pd.DataFrame()
data_alter = pd.DataFrame()
data_alter2 = pd.DataFrame()
# df2 dataframe con el resultado
df2 = pd.DataFrame()
data = pd.DataFrame()

# dataframes con los eventos qtq y qb
df_qtq_ref = pd.DataFrame()
df_qtq_alt = pd.DataFrame()
df_qb_ref = pd.DataFrame()
df_qb_alt = pd.DataFrame()

# esto es provisional
RH = True
RQ = True

"""#ahora si el código

ponemos esto para la entrada de datos de manera provisional pero eso eventualmente lo tiene que hacer el código en react, aunque no se de que manera entra desde el react
"""

df_prueba = 5

# print(verificar_columnas(read_data2))

# read_data2=read_data2[['Latitud','Altitud']]

# p_read_data2=read_data2[['Valor','Fecha']]

# p_read_data2

data

# data

# read_data2=pd.read_csv(r"/content/drive/MyDrive/Drive_SIHU/6. Proyectos/Proyecto 05_Caudal Ambiental/Estaciones/Estaciones Seleccionadas/Nuevas series/barranco murcielago - 32157060.csv",header=0)
# read_data3=pd.read_csv(r"/content/drive/MyDrive/Drive_SIHU/6. Proyectos/Proyecto 05_Caudal Ambiental/Estaciones/Estaciones Seleccionadas/Nuevas series/La Macarena - 32037030.csv",header=0)
# data=pd.read_csv(r"/content/drive/MyDrive/La Macarena - 32037030.csv",header=0)

# base=process_df(read_data2,read_data3,(4,5))

# a=prin_func(read_data2,read_data3,(4,5))

# a

# base=organize_df(read_data)
# summarize_missing_values(base)

# aqui voy
